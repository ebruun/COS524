{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6GoBeftonJa"
   },
   "source": [
    "# Preprocessing Code for Twitter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3018,
     "status": "ok",
     "timestamp": 1611975915839,
     "user": {
      "displayName": "Siena Dumas Ang",
      "photoUrl": "",
      "userId": "15369003819354521451"
     },
     "user_tz": 300
    },
    "id": "dKW_ND7xwJqi",
    "outputId": "bb13946e-26b0-4b2b-c5d9-6afe590468c3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/edvardbruun/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     /Users/edvardbruun/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /Users/edvardbruun/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /Users/edvardbruun/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#!pip install emoji\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import string\n",
    "import nltk\n",
    "import emoji\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "stop_words = set(stopwords.words('english')) - {'all'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1611975918225,
     "user": {
      "displayName": "Siena Dumas Ang",
      "photoUrl": "",
      "userId": "15369003819354521451"
     },
     "user_tz": 300
    },
    "id": "cunU8zjb5CTB"
   },
   "outputs": [],
   "source": [
    "# Gets the part of speech tag of word for lemmatization\n",
    "# This function is based on code from:\n",
    "#   https://www.machinelearningplus.com/nlp/lemmatization-examples-python/\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "# Preprocesses the tweets text\n",
    "# This function is based on code from:\n",
    "#   https://www.pluralsight.com/guides/building-a-twitter-sentiment-analysis-in-python\n",
    "def preprocess_text(tweet):\n",
    "    # Changes emojis to words\n",
    "    tweet = emoji.demojize(tweet,  delimiters=(' ', ' '))\n",
    "    # Removes 'RT' from tweet\n",
    "    tweet = re.sub(r'RT[\\s]+', '', tweet)\n",
    "    # Removes capitalization\n",
    "    tweet = tweet.lower()\n",
    "    # Removes urls & user mentions from tweet\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+|\\@\\w+\", ' ', tweet, flags=re.MULTILINE)\n",
    "    # Removes punctuation\n",
    "    tweet = re.sub(r'\\p{P}+', '', tweet)\n",
    "    # Removes stopwords\n",
    "    tokens = [w for w in word_tokenize(tweet) if not w in stop_words]\n",
    "    # Perfoms lemmatization on tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_words = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in tokens]\n",
    "    return \" \".join(lemma_words)\n",
    "\n",
    "# Preprocesses the text of the Tweets in the df and returns the df\n",
    "# By default, this removes the Tweets with the \"neither\" label\n",
    "def preprocess_df(df, remove_neither=True):\n",
    "  idx = \"text\"\n",
    "  length = len(df[idx])\n",
    "  for ii in range(length):\n",
    "    tweet = str(df[idx][ii])\n",
    "    df.loc[ii, idx] = preprocess_text(tweet)\n",
    "  if (remove_neither):\n",
    "    return df[df['BLM'] != \"neither\"]\n",
    "  else:\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 18579,
     "status": "ok",
     "timestamp": 1611975981373,
     "user": {
      "displayName": "Siena Dumas Ang",
      "photoUrl": "",
      "userId": "15369003819354521451"
     },
     "user_tz": 300
    },
    "id": "Ow-WoTXPkSts",
    "outputId": "db94f59c-f566-4576-89ed-37658ff7d315"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'method' and 'int'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-26b7f22b2c17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtotal_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_rows\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'method' and 'int'"
     ]
    }
   ],
   "source": [
    "# Retrieves and preprocesses the training dataset\n",
    "path = \"./train.csv\" # Path to train.csv\n",
    "train_df = pd.read_csv(path)\n",
    "train_df.fillna(\"\", inplace=True) # fills any NaN values with empty strings\n",
    "train_df = preprocess_df(train_df)\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1611975982347,
     "user": {
      "displayName": "Siena Dumas Ang",
      "photoUrl": "",
      "userId": "15369003819354521451"
     },
     "user_tz": 300
    },
    "id": "noEV2VuUgzmj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uses a CountVectorizer to construct bag-of-words matrix\n",
    "vectorizer = CountVectorizer() # Add a comment about the max_features & ngram_range parameters\n",
    "\n",
    "# train_vocab is an 2d array of the vocab from the training dataset \n",
    "train_vocab = vectorizer.fit_transform(train_df['text']).toarray()\n",
    "\n",
    "# train_vocab_df is a dataframe where the element ij is the number of times word j occurred in Tweet i\n",
    "train_vocab_df = pd.DataFrame(train_vocab, columns=vectorizer.get_feature_names())\n",
    "train_labels = train_df['BLM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1611976100972,
     "user": {
      "displayName": "Siena Dumas Ang",
      "photoUrl": "",
      "userId": "15369003819354521451"
     },
     "user_tz": 300
    },
    "id": "eXTcy6d5Qq3d",
    "outputId": "770a61f8-cb83-476e-d61b-fbfad68e42d9"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   created_at                                           hashtags  \\\n",
       "0  2013-08-05  BlackLivesMatter BrownLivesMatter Every28Hours...   \n",
       "2  2013-08-30                                   blacklivesmatter   \n",
       "3  2013-08-30                             BlackLivesMatter BBW13   \n",
       "4  2013-08-30                                   BlackLivesMatter   \n",
       "5  2013-08-30                             BlackLivesMatter BBW13   \n",
       "\n",
       "                                                text       BLM  \n",
       "0  let talk state violence youth color blacklives...  positive  \n",
       "2  mt show kid positive image black people build ...  positive  \n",
       "3     q1 big parent influence blacklivesmatter bbw13  positive  \n",
       "4  a10 breastfeeding life love crucial beautiful ...  positive  \n",
       "5  new people jumping cohosting blacklivesmatter ...  positive  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created_at</th>\n      <th>hashtags</th>\n      <th>text</th>\n      <th>BLM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2013-08-05</td>\n      <td>BlackLivesMatter BrownLivesMatter Every28Hours...</td>\n      <td>let talk state violence youth color blacklives...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2013-08-30</td>\n      <td>blacklivesmatter</td>\n      <td>mt show kid positive image black people build ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2013-08-30</td>\n      <td>BlackLivesMatter BBW13</td>\n      <td>q1 big parent influence blacklivesmatter bbw13</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2013-08-30</td>\n      <td>BlackLivesMatter</td>\n      <td>a10 breastfeeding life love crucial beautiful ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2013-08-30</td>\n      <td>BlackLivesMatter BBW13</td>\n      <td>new people jumping cohosting blacklivesmatter ...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "train_df.head()\n",
    "#print (train_labels.count() + 1)\n",
    "\n",
    "#train_vocab_df.head()\n",
    "#print (train_vocab_df.count() + 1)\n",
    "\n",
    "#train_labels.head()\n",
    "#print (train_labels.count() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 5585,
     "status": "ok",
     "timestamp": 1611975986990,
     "user": {
      "displayName": "Siena Dumas Ang",
      "photoUrl": "",
      "userId": "15369003819354521451"
     },
     "user_tz": 300
    },
    "id": "aHgyWq_RIroz"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   created_at                                        hashtags  \\\n",
       "0  2013-08-30                                BlackLivesMatter   \n",
       "1  2014-08-02                     RememberTynirah Amnesty2014   \n",
       "2  2014-08-15        Ferguson NMOS14 BlackLivesMatter Atlanta   \n",
       "3  2014-08-17  lgbtq Ferguson blacklivesmatter outrage racism   \n",
       "4  2014-08-18                BlackLivesMatter PeaceInFerguson   \n",
       "\n",
       "                                                text       BLM  \n",
       "0  a3 big challenge find balance ambitious want p...  positive  \n",
       "1  remembertynirah all girl deserve chance all li...  positive  \n",
       "2  national moment silence atlanta ferguson nmos1...  positive  \n",
       "3  hey big shout lgbtq solidarity ferguson blackl...  positive  \n",
       "4  share sunday sermon tenacious nonconformist fa...  positive  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created_at</th>\n      <th>hashtags</th>\n      <th>text</th>\n      <th>BLM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2013-08-30</td>\n      <td>BlackLivesMatter</td>\n      <td>a3 big challenge find balance ambitious want p...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2014-08-02</td>\n      <td>RememberTynirah Amnesty2014</td>\n      <td>remembertynirah all girl deserve chance all li...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2014-08-15</td>\n      <td>Ferguson NMOS14 BlackLivesMatter Atlanta</td>\n      <td>national moment silence atlanta ferguson nmos1...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2014-08-17</td>\n      <td>lgbtq Ferguson blacklivesmatter outrage racism</td>\n      <td>hey big shout lgbtq solidarity ferguson blackl...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2014-08-18</td>\n      <td>BlackLivesMatter PeaceInFerguson</td>\n      <td>share sunday sermon tenacious nonconformist fa...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Retrieves and preprocesses the test dataset\n",
    "path = \"./test.csv\" # Path to Test_dataset.csv\n",
    "test_df = pd.read_csv(path)\n",
    "test_df.fillna(\"\", inplace=True) # fills any NaN values with empty strings\n",
    "test_df = preprocess_df(test_df)\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 5585,
     "status": "ok",
     "timestamp": 1611975986992,
     "user": {
      "displayName": "Siena Dumas Ang",
      "photoUrl": "",
      "userId": "15369003819354521451"
     },
     "user_tz": 300
    },
    "id": "hs9kGIt-_J22"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10614\n10614\n"
     ]
    }
   ],
   "source": [
    "# Uses the vocab from the training dataset to vectorize the test dataset\n",
    "test_vocab = vectorizer.transform(test_df['text']).toarray()\n",
    "\n",
    "# test_vocab_df is a dataframe where the element ij is the number of times word j\n",
    "# occurred in Tweet i\n",
    "test_vocab_df = pd.DataFrame(test_vocab, columns=vectorizer.get_feature_names())\n",
    "test_labels = test_df['BLM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    positive\n",
       "1    positive\n",
       "2    positive\n",
       "3    positive\n",
       "4    positive\n",
       "Name: BLM, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "test_vocab_df.head()\n",
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5577,
     "status": "ok",
     "timestamp": 1611975986992,
     "user": {
      "displayName": "Siena Dumas Ang",
      "photoUrl": "",
      "userId": "15369003819354521451"
     },
     "user_tz": 300
    },
    "id": "6xW0Zv5PAf1x",
    "outputId": "8f895ece-4fb2-4072-d5f7-332444934bee"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of neither Tweets in training: 0\nNumber of positive Tweets in training: 5528\nNumber of negative Tweets in training: 1219\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of neither Tweets in training: {len(train_df[train_df['BLM'] == 'neither'])}\")\n",
    "print(f\"Number of positive Tweets in training: {len(train_df[train_df['BLM'] == 'positive'])}\")\n",
    "print(f\"Number of negative Tweets in training: {len(train_df[train_df['BLM'] == 'negative'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5749,
     "status": "ok",
     "timestamp": 1611975987172,
     "user": {
      "displayName": "Siena Dumas Ang",
      "photoUrl": "",
      "userId": "15369003819354521451"
     },
     "user_tz": 300
    },
    "id": "Funzv_LhBBPI",
    "outputId": "cdaaf234-c365-4002-8e4d-7f5f4135a2d9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of neither Tweets in test: 0\nNumber of positive Tweets in test: 1383\nNumber of negative Tweets in test: 305\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of neither Tweets in test: {len(test_df[test_df['BLM'] == 'neither'])}\")\n",
    "print(f\"Number of positive Tweets in test: {len(test_df[test_df['BLM'] == 'positive'])}\")\n",
    "print(f\"Number of negative Tweets in test: {len(test_df[test_df['BLM'] == 'negative'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "preprocessing.ipynb",
   "provenance": [
    {
     "file_id": "1kNYLYMj2vowrtHEcjI6ebAbwCWdHIR4_",
     "timestamp": 1601231066833
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}